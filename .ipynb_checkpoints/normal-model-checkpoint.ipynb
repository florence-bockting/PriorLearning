{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d282108a-0c8c-4f56-844f-4bdc5e204751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flobo\\anaconda3\\envs\\MakeMyPrior\\lib\\site-packages\\bayesflow\\trainers.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import patsy as pa\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "from MakeMyPrior.elicitation_wrapper import expert_model\n",
    "from MakeMyPrior.training import trainer\n",
    "from MakeMyPrior.helper_functions import group_obs, Exponential_unconstrained, Normal_unconstrained\n",
    "from MakeMyPrior.user_config import target_config, target_input\n",
    "from MakeMyPrior.plot_helpers import plot_loss, plot_convergence, plot_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9721e0-7d32-4ce2-9972-38c504f8c3b8",
   "metadata": {},
   "source": [
    "## User specification\n",
    "\n",
    "### General variables for the learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670376f5-5e7e-4f0a-8a58-84fad3a0fc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 256,\n",
       " 'rep': 600,\n",
       " 'epochs': 6,\n",
       " 'view_ep': 1,\n",
       " 'lr_decay': False,\n",
       " 'lr0': 0.01,\n",
       " 'lr_min': 0.01,\n",
       " 'loss_dimensions': 'm,n:B',\n",
       " 'loss_scaling': 'unscaled',\n",
       " 'method': 'hyperparameter_learning'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_config = dict(                    \n",
    "    B = 2**8,                          \n",
    "    rep = 600,                         \n",
    "    epochs = 6,#00,                      \n",
    "    view_ep = 1,\n",
    "    lr_decay = False,\n",
    "    lr0 = 0.01, \n",
    "    lr_min = 0.01, \n",
    "    loss_dimensions = \"m,n:B\",          \n",
    "    loss_scaling = \"unscaled\",         \n",
    "    method = \"hyperparameter_learning\"  \n",
    "    )\n",
    "    \n",
    "user_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99423e7b-457c-450e-b69a-193f28b663a6",
   "metadata": {},
   "source": [
    "### Design matrix\n",
    "\n",
    "(Only the first 10 observations are presented.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f8223b-3f12-4511-999e-25e088ca9ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flobo\\anaconda3\\envs\\MakeMyPrior\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 6), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 1., 0.],\n",
       "       [1., 1., 0., 1., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0.],\n",
       "       [1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# design matrix\n",
    "X =  pa.dmatrix(\"a*b\", pa.balanced(a = 2, b = 3, repeat = 60))\n",
    "dmatrix = tf.cast(X, dtype = tf.float32)\n",
    "# contrast matrix\n",
    "cmatrix = dmatrix[0:dmatrix.shape[1], :]\n",
    "\n",
    "# show first 10 rows\n",
    "dmatrix[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85d199-7a6e-417b-8553-e465a2951260",
   "metadata": {},
   "source": [
    "### Generative model\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "    y_i &\\sim \\textrm{Normal}(\\theta_i, s) \\\\\n",
    "    \\theta_i &= \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + \\beta_4x_4 + \\beta_5x_5\\\\\n",
    "    \\beta_k &\\sim \\textrm{Normal}(\\mu_k, \\sigma_k) \\quad \\textrm{ for }k=0,\\ldots,5\\\\\n",
    "     s &\\sim \\textrm{Exponential}(\\nu)\\\\\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "### Prior distributions\n",
    "\n",
    "Specify...\n",
    "\n",
    "-   prior distribution family for model parameters\n",
    "-   distributions for initializing hyperparameter values of parametric prior distributions\n",
    "-   prior distribution of ideal expert with hyperparameter values representing the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c610c5-ba5b-424e-83f4-93ca23d95042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true hyperparameter values for ideal_expert\n",
    "true_mu = [0.12, 0.15, -0.02, -0.03, -0.02, -0.04]\n",
    "true_sigma = [0.02, 0.02, 0.06, 0.06, 0.03, 0.03]\n",
    "true_nu = 9.\n",
    "\n",
    "# model parameters\n",
    "parameters_dict = dict()\n",
    "for i in range(6):\n",
    "    parameters_dict[f\"beta_{i}\"] = {\n",
    "            \"family\":  Normal_unconstrained(),\n",
    "            \"true\": tfd.Normal(true_mu[i], true_sigma[i]),\n",
    "            \"initialization\": [tfd.Normal(0.,0.1)]*2\n",
    "            }\n",
    "parameters_dict[\"sigma\"] = {\n",
    "        \"family\": Exponential_unconstrained(user_config[\"rep\"]),\n",
    "        \"true\": tfd.Exponential(true_nu),\n",
    "        \"initialization\": [tfd.Normal(0.,0.1)]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbaa1b-df1f-49e6-9f6b-b68880323c8c",
   "metadata": {},
   "source": [
    "### Generative model\n",
    "\n",
    "Necessary Input-Output structure for continuous likelihood:\n",
    "\n",
    "-   **Input**: `parameters`\n",
    "-   **Output**: `likelihood`, `ypred`, `epred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6bd400-2009-48ab-a35b-99701e02fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generative model\n",
    "class GenerativeModel(tf.Module):\n",
    "    def __call__(self, \n",
    "                 parameters, # obligatory: samples from prior distributions; tf.Tensor\n",
    "                 dmatrix,    # optional: design matrix; tf.Tensor\n",
    "                 cmatrix,    # optional: contrast matrix; tf.Tensor\n",
    "                 **kwargs    # obligatory: possibility for further keyword arguments is needed \n",
    "                 ):  \n",
    "        \n",
    "        # compute linear predictor term\n",
    "        epred = parameters[:,:,0:6] @ tf.transpose(dmatrix)\n",
    "        \n",
    "        # define likelihood\n",
    "        likelihood = tfd.Normal(\n",
    "            loc = epred, \n",
    "            scale = tf.expand_dims(parameters[:,:,-1], -1))\n",
    "        \n",
    "        # sample prior predictive data\n",
    "        ypred = likelihood.sample()\n",
    "        \n",
    "        # compute custom target quantity (here: group-differences)\n",
    "        samples_grouped = group_obs(ypred, dmatrix, cmatrix)\n",
    "\n",
    "        # compute mean difference between groups\n",
    "        effect_list = []\n",
    "        diffs = [(0,3), (1,4), (2,5)]\n",
    "        for i in range(len(diffs)):\n",
    "            # compute group difference\n",
    "            diff = tf.math.subtract(\n",
    "                samples_grouped[:, :, :, diffs[i][0]],\n",
    "                samples_grouped[:, :, :, diffs[i][1]],\n",
    "            )\n",
    "            # average over individual obs within each group\n",
    "            diff_mean = tf.reduce_mean(diff, axis=2)\n",
    "            # collect all mean group differences\n",
    "            effect_list.append(diff_mean)\n",
    "\n",
    "        mean_effects = tf.stack(effect_list, axis=-1)\n",
    "        \n",
    "        return dict(likelihood = likelihood,     # obligatory: likelihood; callable\n",
    "                    ypred = ypred,               # obligatory: prior predictive data\n",
    "                    epred = epred,               # obligatory: samples from linear predictor\n",
    "                    mean_effects = mean_effects  # optional: custom target quantity\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7221db4-6ce3-4785-8c5d-8f6a14702587",
   "metadata": {},
   "source": [
    "### Loss components\n",
    "\n",
    "(target quantities, elicitation techniques, combining losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e3acff5-81ff-40e8-a40c-ed475d2d92ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': ['R2', 'group_means', 'mean_effects'],\n",
       " 'elicitation': ['histogram', 'quantiles', 'quantiles'],\n",
       " 'combine_loss': ['all', 'by-group', 'by-group'],\n",
       " 'custom_target_function': [<function __main__.custom_r2(ypred, epred, **kwargs)>,\n",
       "  None,\n",
       "  None],\n",
       " 'internal_loss': [None, None, None],\n",
       " 'quantiles_specs': [(10, 20, 30, 40, 50, 60, 70, 80, 90),\n",
       "  (10, 20, 30, 40, 50, 60, 70, 80, 90)]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a custom function using the output from the generative model   \n",
    "def custom_r2(ypred, epred, **kwargs):\n",
    "    return tf.math.divide(tf.math.reduce_variance(epred, axis = -1), \n",
    "                          tf.math.reduce_variance(ypred, axis = -1))\n",
    "\n",
    "# specify target quantity, elicitation technique and loss combination\n",
    "t1 = target_config(target=\"R2\", \n",
    "                   elicitation=\"histogram\",\n",
    "                   combine_loss=\"all\",\n",
    "                   custom_target_function = custom_r2)\n",
    "t2 = target_config(target=\"group_means\", \n",
    "                   elicitation=\"quantiles\", \n",
    "                   combine_loss=\"by-group\", \n",
    "                   quantiles_specs = (10, 20, 30, 40, 50, 60, 70, 80, 90))\n",
    "t3 = target_config(target=\"mean_effects\", \n",
    "                   elicitation=\"quantiles\",\n",
    "                   combine_loss=\"by-group\",\n",
    "                   quantiles_specs = (10, 20, 30, 40, 50, 60, 70, 80, 90))\n",
    "\n",
    "target_info = target_input(t1, t2, t3)\n",
    "\n",
    "target_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c13953-66e5-4572-a452-d9e356fb7b34",
   "metadata": {},
   "source": [
    "### Number and Shape of loss components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a664b9e-285e-4862-b65e-1e7b58ff4aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss component 0, with shape =  (1, 600)\n",
      "loss component 1, with shape =  (1, 9)\n",
      "loss component 2, with shape =  (1, 9)\n",
      "loss component 3, with shape =  (1, 9)\n",
      "loss component 4, with shape =  (1, 9)\n",
      "loss component 5, with shape =  (1, 9)\n",
      "loss component 6, with shape =  (1, 9)\n",
      "loss component 7, with shape =  (1, 9)\n",
      "loss component 8, with shape =  (1, 9)\n",
      "loss component 9, with shape =  (1, 9)\n"
     ]
    }
   ],
   "source": [
    "# ideal expert\n",
    "expert_res_list, prior_pred_res = expert_model(1, user_config[\"rep\"],\n",
    "                               parameters_dict, GenerativeModel, target_info,\n",
    "                               method = \"ideal_expert\",\n",
    "                               dmatrix = dmatrix,\n",
    "                               cmatrix = cmatrix,\n",
    "                               dmatrix_fct = dmatrix)\n",
    "                               \n",
    "for i in range(len(expert_res_list)):\n",
    "  print(f\"loss component {i}, with shape = \", expert_res_list[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c4d22-a5be-4a31-bebf-30c786126d75",
   "metadata": {},
   "source": [
    "## Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d08a50f-cb3f-441e-8d70-904bb8c0628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loss components: 10\n",
      "Epoch: 0, loss: 0.78789, lr: 0.010000\n",
      "Epoch: 1, loss: 0.77852, lr: 0.010000\n",
      "Epoch: 2, loss: 0.76819, lr: 0.010000\n",
      "Epoch: 3, loss: 0.75723, lr: 0.010000\n",
      "Epoch: 4, loss: 0.75123, lr: 0.010000\n",
      "Epoch: 5, loss: 0.74095, lr: 0.010000\n"
     ]
    }
   ],
   "source": [
    "# simulation model and training\n",
    "res_dict = trainer(expert_res_list, user_config[\"B\"], user_config[\"rep\"],\n",
    "                   parameters_dict, user_config[\"method\"], GenerativeModel,\n",
    "                   target_info, user_config, loss_balancing = True,\n",
    "                   dmatrix = dmatrix, cmatrix = cmatrix, dmatrix_fct = dmatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
